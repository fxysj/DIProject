from transformers import AutoTokenizer, AutoModelForCausalLM
from huggingface_hub import snapshot_download
import shutil
import os

# è®¾ç½®æ¨¡å‹åç§°å’Œä¿å­˜è·¯å¾„
model_id = "Qwen/Qwen3-8B"
save_dir = "./Qwen3-8B-offline"

# Step 1: ä¸‹è½½æ•´ä¸ªæ¨¡å‹å¿«ç…§åˆ°æœ¬åœ°ç¼“å­˜ç›®å½•ï¼ˆå«æƒé‡ã€é…ç½®ã€tokenizerç­‰ï¼‰
print("ğŸ“¦ Downloading model from Hugging Face Hub...")
local_dir = snapshot_download(repo_id=model_id, local_dir=save_dir, local_dir_use_symlinks=False)

print(f"âœ… æ¨¡å‹å·²ä¿å­˜åˆ°ï¼š{local_dir}")
