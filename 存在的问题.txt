❌ 二、问题也很明显：没有抓住主要矛盾，难以形成合力
毛泽东在《矛盾论》中讲得非常清楚：“在每一复杂事物中，都有一种矛盾是主要的。”

简历中虽然展示了广泛的推理栈支持，但缺少一个“核心技术主线”作为整合的旗帜。

比如：

如果以 VLLM 作为主轴，是否在高并发+流式推理场景里形成闭环？

如果主攻 TensorRT-LLM，是否围绕模型结构+算子融合+GPU特性做了深入调优？

目前看更像是：这也做，那也做，但没有组织兵力打一场“推理歼灭战”。

这违背了毛泽东一贯倡导的：“打歼灭战，不打消耗战；集中优势兵力，突破一点。”


三、从群众路线出发：是否考虑了“场景中的人民性”？
毛泽东思想强调：一切从人民出发。对应到技术场景，就是：你的推理优化，是为了解决谁的问题？是给什么场景带来确定性提升？

这份简历没有明确场景指向，略显“脱离群众”，缺乏如下关切：

是为SaaS类的通用推理服务降本？

还是为端侧设备节能？还是RAG系统的低延迟响应？

具体压测指标？延迟下降百分比？吞吐上升的具体业务含义？

缺乏这些，就是典型的“技术脱离群众”。

 毛式总结：“摸索可贵，但要集中兵力打歼灭战，别搞技术游击战。”
“一个技术战士，如果东一榔头西一棒子，就像红军初期分散游击，打不出大胜仗。只有抓住主要方向，建立稳固根据地，才能形成技术合围，打出漂亮的推理胜仗。”



职业定位毛式总纲
一句话纲领：集中力量主攻“大模型推理效率革命”，以TensorRT-LLM与VLLM为根据地，打通从模型量化、并行调度到高性能部署的全链路闭环，服务于人民群众在RAG问答、端侧推理、SaaS平台等核心应用场景中的降本增效需要。

✊ 重构版简历（推理方向，毛泽东式）
国际商业机器（中国）有限公司
算法工程师（大模型推理主攻方向）
2021.07 - 至今

一、树立技术根据地：构建推理效率体系
以TensorRT-LLM与VLLM为核心战线，围绕大模型推理中的延迟、吞吐、内存开销三大矛盾，建立量化、并行、加速三位一体的优化策略：

模型压缩战役：推动FP8、INT8精度下量化训练与推理部署，基于TensorRT/cutlass完成高性能部署；

推理战术协同：KV Cache、流式推理（VLLM/SGLang）优化上下文复用，提升Token生成速度；

深度融合硬件特性：在NVIDIA A100与L40S上完成TP/PP/DP多维并行调度实验，优化跨卡通信瓶颈。

二、组织技术歼灭战：从平台到场景，打通闭环
搭建高性能推理服务平台：

基于Triton + ONNX + TensorRT-LLM，构建GPU高效推理微服务；

统一调度，统一指标监控：基于Prometheus+Wandb实现训练+推理全过程指标闭环；

推出推理能力SaaS化：对接公司级多业务（语义搜索、RAG问答、OCR后处理）场景，实现端到端交付。

推出高可靠推理评估体系：构建多模型TTFT/吞吐/并发压测基线，集成ModelScope+Wandb完成自动对比、效果可视化。

三、以人民为中心：场景驱动的实用主义实践
面向群众的三个典型场景：

文档问答场景：结合Qwen2-7B + PaddleOCR，RAG系统打通文档抽取→查询理解→生成回答全链路，服务内部知识库问答场景；

移动端推理场景：基于INT8量化模型与OlLlama结合，探索边端部署可行性；

通用API服务化：部署高并发通用推理API平台，支持多模型并行调度，响应不同业务单位调用需求。

四、群众路线+实事求是：分布式基础设施建设
打牢推理之基石：主导Kubernetes推理服务集群建设，支持CPU+GPU混合调度；

引入Nginx + Kafka消息通道，服务调用量突破万级请求；

推进RAG系统的服务化接入，开发基于Spring Boot的REST接口，提升产品交付能力。



===========================
📌 总结语（毛式风格）
在大模型推理这场新技术的“人民战争”中，我不做技术游击队，而是构建根据地、发动群众、主攻主要矛盾，形成从训练到部署的推理铁军。我的目标不是炫技，而是解决问题，服务人民，用推理的战斗力支撑智能应用的生产力！

🧠 重构版简历更新（增加数据处理，毛式风格）
国际商业机器（中国）有限公司
算法工程师（大模型推理主攻方向）
2021.07 - 至今

一、推理为纲，数据为本：构建数据支前系统
“把数据当作武器来准备”，打通数据采集、预处理、缓存、落盘、调度、并行加载全过程，实现训练与推理资源的动态调配与高效复用。

组织完成海量Token数据清洗与预处理（超过3000万条）：

编写多线程加速清洗管道，按模型输入需求格式化jsonl → tensor；

对接HuggingFace Datasets接口构建自定义数据加载类，支持多进程分布加载。

统一数据缓存机制：

构建基于NVIDIA DALI与Arrow格式的数据高速读取链路，提升I/O性能50%以上；

对接DeepSpeed Dataloader + KV缓存机制，实现推理时冷启动→热读的分层调度。

引入高性能图数据库（Neo4j）构建知识图谱，为RAG检索提供结构化基础；

在问答系统中落地 Chunk切分 + Embedding入库 + Merge Cell拼接 策略，提升召回率和答案整合质量；

构建大规模模型训练样本自动标注系统：集成PaddleOCR + LLM + 正则预标注，提高训练语料合规性与覆盖率。

二、统筹训练-推理-评估一体化闭环
训练数据生产 + 模型SFT训练 + 多模型推理评估 全链条数据控制：

调度Qwen2系列、LLaMA系列、Claude系列模型进行SFT训练；

利用Wandb统一记录每轮训练/推理精度、时延、损失值曲线，辅助策略回溯；

使用EvalScope构建性能评测平台，实现各类模型横向对比、推理精度统计与调优自动化。

三、建设分布式数据基础设施
构建分布式Kubernetes平台，按需分发数据副本到计算节点；

基于Kafka搭建流式数据服务，推理输入/输出异步写入MySQL + ElasticSearch，提升系统抗压能力；

在RAG场景中开发数据采集—知识抽取—语义向量化—检索匹配流水线，服务上层检索问答系统。

🎯 简历亮点毛式总结句
数据是大模型推理的“粮草”、也是训练的“钢铁”，我将“从一粒Token做起”，从数据采集、清洗、切分、存储到分发调度，构筑数据-推理的统一战线，确保前线模型有粮可用、有算可依，打通从数据到效果的“人民通道”。