{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-08T06:12:18.635809Z",
     "start_time": "2025-04-08T06:12:18.235725Z"
    }
   },
   "source": [
    "from modelscope.models import Model\n",
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.utils.constant import Tasks\n",
    "from modelscope.preprocessors import TokenClassificationTransformersPreprocessor\n",
    "\n",
    "model_id = 'iic/nlp_structbert_word-segmentation_chinese-base'\n",
    "model = Model.from_pretrained(model_id)\n",
    "tokenizer = TokenClassificationTransformersPreprocessor(model.model_dir)\n",
    "pipeline_ins = pipeline(task=Tasks.word_segmentation, model=model, preprocessor=tokenizer)\n",
    "result = pipeline_ins(input=\"今天天气不错，适合出去游玩\")\n",
    "print (result)\n",
    "# {'output': '今天 天气 不错 ， 适合 出去 游玩'}"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sin/PycharmProjects/DIProject/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'addict'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mmodelscope\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mmodels\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Model\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mmodelscope\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mpipelines\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m pipeline\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mmodelscope\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mconstant\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Tasks\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DIProject/.venv/lib/python3.11/site-packages/modelscope/models/__init__.py:10\u001B[39m\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mmodelscope\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mimport_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (is_torch_available,\n\u001B[32m      8\u001B[39m                                            is_transformers_available)\n\u001B[32m      9\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m audio, cv, multi_modal, nlp\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mbase\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Head, Model\n\u001B[32m     11\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mbuilder\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m BACKBONES, HEADS, MODELS, build_model\n\u001B[32m     13\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_torch_available():\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DIProject/.venv/lib/python3.11/site-packages/modelscope/models/base/__init__.py:4\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# Copyright (c) Alibaba, Inc. and its affiliates.\u001B[39;00m\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mmodelscope\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mimport_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m is_torch_available\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mbase_head\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m *  \u001B[38;5;66;03m# noqa F403\u001B[39;00m\n\u001B[32m      5\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mbase_model\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m *  \u001B[38;5;66;03m# noqa F403\u001B[39;00m\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_torch_available():\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DIProject/.venv/lib/python3.11/site-packages/modelscope/models/base/base_head.py:5\u001B[39m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mabc\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ABC, abstractmethod\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtyping\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Any, Dict, Union\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mmodelscope\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mmodels\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mbase\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mbase_model\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Model\n\u001B[32m      6\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mmodelscope\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mconfig\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ConfigDict\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mmodelscope\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mlogger\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m get_logger\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DIProject/.venv/lib/python3.11/site-packages/modelscope/models/base/base_model.py:9\u001B[39m\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mmodelscope\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mhub\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01msnapshot_download\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m snapshot_download\n\u001B[32m      8\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mmodelscope\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mmetainfo\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Tasks\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mmodelscope\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mmodels\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mbuilder\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m build_backbone, build_model\n\u001B[32m     10\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mmodelscope\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mautomodel_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (can_load_by_ms,\n\u001B[32m     11\u001B[39m                                               try_to_load_hf_model)\n\u001B[32m     12\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mmodelscope\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mconfig\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Config, ConfigDict\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DIProject/.venv/lib/python3.11/site-packages/modelscope/models/builder.py:3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# Copyright (c) Alibaba, Inc. and its affiliates.\u001B[39;00m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mmodelscope\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mmetainfo\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Models\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mmodelscope\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mconfig\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ConfigDict\n\u001B[32m      4\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mmodelscope\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mconstant\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Tasks\n\u001B[32m      5\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mmodelscope\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mimport_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m INDEX_KEY, LazyImportModule\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/DIProject/.venv/lib/python3.11/site-packages/modelscope/utils/config.py:17\u001B[39m\n\u001B[32m     14\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtypes\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m FunctionType\n\u001B[32m     15\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtyping\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Dict, Union\n\u001B[32m---> \u001B[39m\u001B[32m17\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01maddict\u001B[39;00m\n\u001B[32m     18\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mjson\u001B[39;00m\n\u001B[32m     20\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mmodelscope\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mconstant\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ConfigFields, ModelFile\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'addict'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os.path as osp\n",
    "from modelscope.metainfo import Trainers\n",
    "from modelscope.trainers import build_trainer\n",
    "from modelscope.msdatasets import MsDataset\n",
    "from modelscope.utils.constant import DownloadMode\n",
    "\n",
    "# Step 1: 数据集准备，可以使用modelscope上已有的数据集，也可以自己在本地构建COCO数据集\n",
    "train_dataset = MsDataset.load('person_detection_for_train', namespace=\"modelscope\", split='train', download_mode=DownloadMode.FORCE_REDOWNLOAD)\n",
    "val_dataset = MsDataset.load('person_detection_for_train', namespace=\"modelscope\", split='validation', download_mode=DownloadMode.FORCE_REDOWNLOAD)\n",
    "\n",
    "# Step 2: 相关参数设置\n",
    "train_root_dir = train_dataset.config_kwargs['split_config']['train']\n",
    "val_root_dir = val_dataset.config_kwargs['split_config']['validation']\n",
    "train_img_dir = osp.join(train_root_dir, 'images')\n",
    "val_img_dir = osp.join(val_root_dir, 'images')\n",
    "train_anno_path = osp.join(train_root_dir, 'train.json')\n",
    "val_anno_path = osp.join(val_root_dir, 'val.json')\n",
    "kwargs = dict(\n",
    "            model='iic/cv_tinynas_human-detection_damoyolo', # 使用DAMO-YOLO-S模型\n",
    "            gpu_ids=[  # 指定训练使用的gpu\n",
    "                0,\n",
    "            ],\n",
    "            batch_size=2, # batch_size, 每个gpu上的图片数等于batch_size // len(gpu_ids)\n",
    "            max_epochs=3, # 总的训练epochs\n",
    "            num_classes=1, # 自定义数据中的类别数\n",
    "            load_pretrain=True, # 是否载入预训练模型，若为False，则为从头重新训练\n",
    "            base_lr_per_img=0.001, # 每张图片的学习率，lr=base_lr_per_img*batch_size\n",
    "            train_image_dir=train_img_dir, # 训练图片路径\n",
    "            val_image_dir=val_img_dir, # 测试图片路径\n",
    "            train_ann=train_anno_path, # 训练标注文件路径\n",
    "            val_ann=val_anno_path, # 测试标注文件路径\n",
    "            )\n",
    "\n",
    "# Step 3: 开启训练任务\n",
    "trainer = build_trainer(\n",
    "            name=Trainers.tinynas_damoyolo, default_args=kwargs)\n",
    "trainer.train()"
   ],
   "id": "de62f93eecd615bc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#电商分词器",
   "id": "b4d8a25eb584e07a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from modelscope.models import Model\n",
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.utils.constant import Tasks\n",
    "# Version less than 1.1 please use TokenClassificationPreprocessor\n",
    "from modelscope.preprocessors import TokenClassificationTransformersPreprocessor\n",
    "\n",
    "model_id = 'iic/nlp_structbert_word-segmentation_chinese-base-ecommerce'\n",
    "model = Model.from_pretrained(model_id)\n",
    "tokenizer = TokenClassificationTransformersPreprocessor(model.model_dir)\n",
    "pipeline_ins = pipeline(task=Tasks.word_segmentation, model=model, preprocessor=tokenizer)\n",
    "result = pipeline_ins(input=\"收腰显瘦黑裙长裙\")\n",
    "print (result)\n",
    "# {'output': '收腰 显瘦 黑裙 长裙'}"
   ],
   "id": "89660e22cbddb7dd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#越南语",
   "id": "c603006364aee0af"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.utils.constant import Tasks\n",
    "\n",
    "word_segmentation_pipeline = pipeline(Tasks.word_segmentation, 'iic/nlp_xlmr_word-segmentation_viet', model_revision='v1.0.0')\n",
    "result = word_segmentation_pipeline('Nền kinh tế lúc ấy đang đứng trước nghịch lý : giá hàng tăng , sản xuất đình trệ , tiền khan hiếm ...')\n",
    "\n",
    "print(result)\n",
    "#{'output': ['Nền', 'kinh tế', 'lúc', 'ấy', 'đang', 'đứng', 'trước', 'nghịch lý', ':', 'giá', 'hàng', 'tăng', ',', 'sản xuất', 'đình trệ', ',', 'tiền', 'khan hiếm', '...'], 'labels': []}"
   ],
   "id": "37e74449d365fdad"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
