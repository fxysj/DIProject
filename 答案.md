# 🔬 AI 算法大模型实战题集应答

本文为「AI 大模型实战题集」的选题详解和适配答案，方便课程实践或工作项目实操开始。

---

## 🧠 题目一：基于 QLoRA 的大模型微调实践

**答案指引：**

- 基于 `transformers` + `peft` + `trl` + `accelerate` 构建训练系统
- 选用数据集：BELLE-2M, Alpaca-zh
- 重点配置：
  - `LoraConfig(r=8, lora_alpha=16, lora_dropout=0.1)`
  - `bnb_config` 含 `load_in_4bit=True`
- 训练时长：2~4 epoch
- 添加后间实时 eval 看训练进度
- 可选与 `DPOTrainer` 进行 RLHF 体验化

**结果评估：**

- BLEU / ROUGE 分数
- 手工清澄后人工评分 (Helpfulness, Relevance, Coherence)

---

## 🧬 题目二：基于本地 BERT 的语义匹配模型

**答案指引：**

- 构造 Siamese BERT (双分支 BERT + cosine 相似度)
- 数据集：LCQMC, PAWS-X, AFQMC
- 训练方式：可以选择 CosineSimilarityLoss 或 TripletLoss
- 应用 Sentence-BERT (通过 mean pooling 得到向量)
- 使用 `sentence-transformers` 实现

**结果评估：**

- AUC/ROC, Accuracy, Recall@k
- 当用于检索时，FAISS ANN + 推理 TopK 

---

## 🧘‍⚖️ 题目三：多模态图文匹配推理系统

**答案指引：**

- 基于 `CLIP` 思路：使用 ViT + BERT/中文 RoBERTa
- 通过 image/text encoder 各自获取 embedding
- 相似度 = cosine(image_emb, text_emb)
- 可使用 pretrain 模型：BAAI/AltCLIP, WenLan, CN-CLIP
- 或自行训练 image-caption 对数据

**结果评估：**

- Recall@1/5/10, Mean Rank
- 清澄扩散图文对比点评估系统精度

---

## ⚙️ 题目四：基于 LLMFactory + VLLM + Unsloth 的高性能推理部署

**答案指引：**

- 基础组成：
  - LLMFactory: 合并接口 + Gateway
  - VLLM: 推理引擎，支持 PagedAttention
  - Unsloth: QLoRA 量化后精简 LLaMA2/3 模型
- 同时支持多种 LLM + OpenAI 接口类型
- 支持 KV-Cache reuse, prompt cache
- 接入 FastAPI / LangChain 实现快速打通 RAG

**结果评估：**

- QPS, Latency, GPU 占用率
- 最大并发支持计算：应对 2000+同时用户

---

## 💊 题目五：基于 GPT-2 的分子语言模型 + AI 药物生成

**答案指引：**

- 数据处理：SMILES 语言格式表示分子结构
- 基于 GPT-2 建立文本生成模型
- 训练：Language Modeling (接续 SMILES 表达)
- 评估指标：QED (药用最优化系数), SA score (合成易性), Novelty
- QSAR 预测：联合 XGBoost/图网 进行性能预测
- Reinforcement Learning 最优化：选择 RL 目标为 QED/SA/重合性

---

若需继续扩展 Bonus 题，或建议系统项目实现，可再提出新需求！