---

### ✅ **面试题 1：基础模型选择**

**问：** 如何选择适合自己任务的大模型基础架构（如 LLaMA、BLOOM、ChatGLM、Qwen 等）？你会关注哪些关键因素？

**考点：**

* 模型规模（参数量） 
* 许可协议（开源与否、商用限制）
* 上游训练语料的偏好
* 模型架构（Decoder-only, Encoder-decoder）
* 与下游任务的适配性（多语言、代码、对话）

---

### ✅ **面试题 2：分布式训练与加速策略**

**问：** 针对 70B 级别的大模型，你如何设计其训练框架？分布式策略（如数据并行、张量并行、流水线并行）和加速技术你如何选择？

**考点：**

* Megatron-LM, Deepspeed, FSDP、ZeRO、Hybrid Parallel
* GPU/TPU 拓扑与并行方式适配
* Mixed Precision（FP16/BF16）
* Gradient Accumulation vs Checkpointing
* Flash Attention、ReLoRA 等训练加速

---

### ✅ **面试题 3：算力架构适配**

**问：** 针对当前主流的 A100（80GB）、H100、Ascend、TPU v4 等设备，你如何评估其训练和推理的能力差异？你在训练时会如何分配任务？

**考点：**

* GPU/TPU 架构差异（HBM带宽、NVLink、SM数量）
* 高速互联（InfiniBand、NVSwitch）
* 单机/多机调度（Slurm、KubeRay、Kubernetes）
* 容错与可恢复策略（例如 Fault Tolerance）

---

### ✅ **面试题 4：数据集对齐与清洗**

**问：** 在训练对话类大模型时，如何处理多源异构数据的格式、标签和质量对齐问题？你通常有哪些数据清洗和标准化手段？

**考点：**

* 指令微调/预训练数据构建（Prompt + Completion）
* 样本权重、重复样本去重
* 损坏样本检测（空样本、编码错误、无意义回复）
* 多语言数据统一格式
* 对齐技术（如DPO/SFT/RLHF）

---

### ✅ **面试题 5：模型训练中的维度问题排查**

**问：** 模型训练中报错：“Expected input shape (B, S, D), but got (B, D)” 或者张量 shape mismatch，这类问题你通常如何排查？

**考点：**

* Input Embedding 输入维度是否统一
* Padding/Mask 是否正确处理
* Position Embedding 长度超限
* torch.nn vs custom module 的 shape 兼容问题
* Batch size 动态调整后的兼容性问题

---

### ✅ **面试题 6（Bonus）：推理部署性能优化**

**问：** 大模型在推理部署时延迟高、显存占用大，通常有哪些手段可以优化推理性能？请简述 3 种方法及其原理。

**考点：**

* 模型量化（INT8, GPTQ, AWQ）
* 模型裁剪（Low-Rank Adaptation, Pruning）
* KV Cache 重用机制
* Batch 推理 vs 流式推理
* 编译器加速（TensorRT, vLLM, ONNX）

---

