1. **医疗数据处理与质量提升**：在AI+制药相关项目里，需要处理海量且复杂的医疗数据，像基因测序数据、临床试验患者的多源异构数据（涵盖影像、检验、病历文本等）。请结合实际经验，谈谈你会采取哪些策略和技术来清理、整合这些数据，以此提升数据质量，为后续的药物研发模型训练提供可靠支撑？例如，在整合不同格式的医疗影像数据时，怎样进行归一化处理，确保数据特征的一致性；对于包含缺失值和异常值的临床检验数据，又会运用哪些方法进行填补和修正？
2. **钱包交易数据特征工程**：针对钱包的交易行为分析和推理，交易数据包含交易时间、金额、交易对手等信息。从数据处理和特征工程的角度出发，你会如何提取、构造有助于分析用户交易模式、风险评估的特征？比如，基于交易时间序列，能否设计出反映用户交易活跃度和规律性的特征；对于交易金额数据，怎样进行特征变换，挖掘出与用户消费能力、风险偏好相关的信息；在考虑交易对手时，如何通过构建图结构特征，分析用户在交易网络中的位置和角色，进而辅助风险判断？
3. **不平衡数据处理策略**：在AI+制药的药物不良反应预测任务中，不良反应发生的样本数量往往远少于未发生的样本，导致数据不平衡，这会严重影响模型的性能。请详细阐述你所了解的处理不平衡数据的方法，并结合该场景分析每种方法的适用性和可能存在的问题。例如，对于过采样方法，如何避免因简单复制少数类样本而导致的模型过拟合；对于欠采样方法，怎样在减少多数类样本时，最大程度保留关键信息；还有基于模型改进的方法，如调整分类器的阈值、采用集成学习算法等，在实际应用中如何进行参数优化和效果评估？
4. **高维数据降维实践**：在分析钱包交易数据时，若考虑众多因素（如交易频率、地理位置、交易类型等），数据维度会迅速增加，带来计算复杂度上升和模型过拟合风险。假设你面临这样的高维交易数据，你会选择哪种降维算法（如主成分分析PCA、线性判别分析LDA、t-SNE等）？请详细说明选择的依据，以及在实际应用过程中如何确定降维的合适维度，怎样评估降维效果对后续模型（如用于交易风险评估的分类模型）性能的影响？例如，在使用PCA进行降维时，如何通过计算特征值贡献率来确定主成分数量；在应用t-SNE降维后，如何通过可视化和定量指标（如轮廓系数、Calinski-Harabasz指数等）判断降维后数据的聚类效果和对模型分类准确率的提升情况？
5. **实时数据处理与更新机制**：在钱包行为实时分析场景中，交易数据不断产生，需要及时处理和更新分析结果。请描述你会搭建怎样的实时数据处理架构和更新机制，以满足对交易风险实时监测和预警的需求？例如，如何选择合适的流计算框架（如Apache Flink、Spark Streaming等）来处理实时交易数据；在数据更新方面，怎样设计增量更新算法，避免重复计算，确保模型能及时反映最新交易行为特征，同时保持模型的稳定性和准确性？在实际部署中，还需要考虑哪些因素（如数据传输延迟、系统容错性等）来保障实时数据处理系统的可靠运行？ 